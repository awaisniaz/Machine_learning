{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mask_detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOxrN5xf9dZBifPjlCN0n1H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/awaisniaz/Machine_learning/blob/master/Mask_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibN-lGBiyQeC"
      },
      "source": [
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTql-1TGyg9F",
        "outputId": "a73ca26f-5afa-4505-e49f-8ddd189cde07"
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dropout,Dense\n",
        "cnn = Sequential([Conv2D(filters=100, kernel_size=(3,3), \n",
        "                    activation='relu'),\n",
        "                    MaxPooling2D(pool_size=(2,2)),\n",
        "                    Conv2D(filters=100, kernel_size=(3,3), \n",
        "                    activation='relu'),\n",
        "                    MaxPooling2D(pool_size=(2,2)),\n",
        "                    Flatten(),\n",
        "                    Dropout(0.5),\n",
        "                    Dense(50),\n",
        "                    Dense(35),\n",
        "                    Dense(2)])\n",
        "cnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc'])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f1146fee790>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "PrcHyJ281ZTU",
        "outputId": "7b7ad274-b50f-498e-c535-339d9fb4cecc"
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "label_dic = {0:'NO Mask',1:'Mask'}\n",
        "color_dict = {0:(0,0,255),1:(0,255,0)}\n",
        "imgSize = 4\n",
        "camera = cv2.VideoCapture(0)\n",
        "classifier = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n",
        "while True:\n",
        "  (rval,im)  = camera.read()\n",
        "  im = cv2.flip(im,1,1)\n",
        "  imgs = cv2.resize(im,(im.shape[1]//imgSize,im.shape[0]//imgSize))\n",
        "\n",
        "  face_rec = classifier.detectMultiScale(imgs)\n",
        "  for in in face_rec:\n",
        "    (x,y,l,w)=im[v*imgSize for v in i]\n",
        "    facceImage = im[y:y+w,x:x+l]\n",
        "    resized = cv2.resize(facceImage,(150,150))\n",
        "    normalized = resized/255.0\n",
        "    reshaped = np.reshape(normalized,(1,150,150,3))\n",
        "    reshaped = np.vstack([reshaped])\n",
        "    result = cnn.predict(reshaped)\n",
        "    label=np.argmax(result,axis=1)[0]\n",
        "        cv2.rectangle(im,(x,y),(x+l,y+w),color_dict[label],2)\n",
        "        cv2.rectangle(im,(x,y-40),(x+l,y),color_dict[label],-1)\n",
        "        cv2.putText(im, labels_dict[label], (x, y-\n",
        "        10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
        "    cv2.imshow('LIVE',im)\n",
        "    key = cv2.waitKey(10)\n",
        "    # stop loop by ESC\n",
        "    if key == 27: # The Esc key\n",
        "        break\n",
        "webcam.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-cda6469aa7fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mimgSize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mcamera\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcamera\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/patches/__init__.py\u001b[0m in \u001b[0;36mcv2_imshow\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \"\"\"\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m   \u001b[0;31m# cv2 stores colors as BGR; convert to RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'cv2.VideoCapture' object has no attribute 'clip'"
          ]
        }
      ]
    }
  ]
}